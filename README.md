# ML-algorithms-from-scratch

This repository contains manual implementations of core machine learning algorithms from scratch using Python and Jupyter Notebooks. No external ML libraries such as scikit-learn are used for the core logic, ensuring a deeper understanding of how each algorithm works under the hood.

## Implemented Algorithms

### Regression

- Linear Regression
- Multiple Linear Regression using Gradient Descent
- Ridge Regression(Least Square method and Gradient Descent method)
- SGD Regressor (Stochastic Gradient Descent)
- Mini-Batch Gradient Descent

### Classification

- Perceptron vs Logistic Regression

### Clustering

- K-Means Clustering

### Dimensionality Reduction

- Principal Component Analysis (Manual Code)

### Ensemble Methods

- AdaBoost
- Gradient Boosting

## Structure

Each algorithm is implemented in a separate Jupyter Notebook with:
- Explanation of the algorithm(whereever needed)
- Step-by-step implementation
- Test cases and performance demonstrations(for comparison with scikit-learn)
